{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b0cc50f",
   "metadata": {},
   "source": [
    "DATA PREPROCESSING FOR ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce96a048",
   "metadata": {},
   "source": [
    "Author: Zeeshan\n",
    "\n",
    "Purpose: Prepare cleaned data for machine learning model\n",
    "\n",
    "Preprocessing tasks:\n",
    "1. Convert data types\n",
    "2. Handle missing values\n",
    "3. Extract date features\n",
    "4. Normalize text fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "419e385d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Loaded29,959 records\n",
      "   Columns:['contract_id', 'pub_date', 'contract_amount', 'bidder_count', 'dept_name', 'proc_method', 'data_source']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Load my cleaned data from previous step\n",
    "data = pd.read_csv('data/processed/cleaned_master_data.csv')\n",
    "print(f\"üì• Loaded{len(data):,} records\")\n",
    "print(f\"   Columns:{data.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc4c6e4",
   "metadata": {},
   "source": [
    "TYPE CONVERSION STRATEGY:\n",
    "\n",
    "Why? ML models need proper data types:\n",
    "- Dates as datetime ‚Üí Extract month, year, day\n",
    "- Amounts as numbers ‚Üí Calculate statistics\n",
    "- Categories as text ‚Üí For grouping analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bccb39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Converting data types...\n",
      "‚úì Date conversion:26205 valid dates\n",
      "‚úì Amount conversion:29959 valid amounts\n",
      "‚úì Bidder conversion:29929 valid counts\n"
     ]
    }
   ],
   "source": [
    "print(\"üîÑ Converting data types...\")\n",
    "\n",
    "# Convert publication date to datetime\n",
    "# Using UTC to handle timezone issues I found in EDA\n",
    "data['pub_date'] = pd.to_datetime(data['pub_date'],\n",
    "                                   errors='coerce',\n",
    "                                   utc=True)\n",
    "# Remove timezone for easier handling\n",
    "data['pub_date'] = data['pub_date'].dt.tz_localize(None)\n",
    "\n",
    "# Ensure amounts are numeric\n",
    "data['contract_amount'] = pd.to_numeric(data['contract_amount'],\n",
    "                                        errors='coerce')\n",
    "\n",
    "# Ensure bidder count is numeric\n",
    "data['bidder_count'] = pd.to_numeric(data['bidder_count'],\n",
    "                                      errors='coerce')\n",
    "\n",
    "# Check results\n",
    "print(f\"‚úì Date conversion:{data['pub_date'].notna().sum()} valid dates\")\n",
    "print(f\"‚úì Amount conversion:{data['contract_amount'].notna().sum()} valid amounts\")\n",
    "print(f\"‚úì Bidder conversion:{data['bidder_count'].notna().sum()} valid counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520b7305",
   "metadata": {},
   "source": [
    "MISSING VALUE STRATEGY (My Rationale):\n",
    "\n",
    "bidder_count: Fill with 1 (single bidder - worst case assumption)\n",
    "proc_method: Fill with 'Unknown' (category for missing)\n",
    "pub_date: Remove rows (can't do time analysis without dates)\n",
    "\n",
    "Why these choices?\n",
    "- Assuming single bidder is conservative (flags more for review)\n",
    "- Unknown category preserves records without making false assumptions\n",
    "- Date is critical for fraud detection - can't fill with fake dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1cece04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Handling missing values...\n",
      "üìä Missing values BEFORE handling:\n",
      "contract_id           0\n",
      "pub_date           3754\n",
      "contract_amount       0\n",
      "bidder_count          0\n",
      "dept_name             0\n",
      "proc_method           0\n",
      "data_source           0\n",
      "dtype: int64\n",
      "\n",
      "‚úì Filled 0 missing bidder counts with 1\n",
      "‚úì Filled 0 missing procurement methods with 'Unknown'\n",
      "\n",
      "‚ö†Ô∏è  Found 3754 rows with missing dates\n",
      "   Removing these rows (dates are critical for fraud analysis)\n",
      "‚úì Removed 3754 rows with missing dates\n",
      "\n",
      "üìä Missing values AFTER handling:\n",
      "contract_id        0\n",
      "pub_date           0\n",
      "contract_amount    0\n",
      "bidder_count       0\n",
      "dept_name          0\n",
      "proc_method        0\n",
      "data_source        0\n",
      "dtype: int64\n",
      "\n",
      "‚úÖ Data ready for feature engineering!\n",
      "   Final record count: 26,205\n",
      "   Columns with no missing values: 7/7\n"
     ]
    }
   ],
   "source": [
    "print(\"üîß Handling missing values...\")\n",
    "\n",
    "# Track missing before\n",
    "print(\"üìä Missing values BEFORE handling:\")\n",
    "print(data.isnull().sum())\n",
    "print()\n",
    "\n",
    "# Fix 1: Fill bidder count (CORRECT METHOD - no inplace)\n",
    "bidder_missing = data['bidder_count'].isna().sum()\n",
    "data = data.copy()  # Avoid SettingWithCopyWarning\n",
    "data['bidder_count'] = data['bidder_count'].fillna(1)  # Modern way\n",
    "print(f\"‚úì Filled {bidder_missing} missing bidder counts with 1\")\n",
    "\n",
    "# Fix 2: Fill procurement method\n",
    "proc_missing = data['proc_method'].isna().sum()\n",
    "data['proc_method'] = data['proc_method'].fillna('Unknown')  # Modern way\n",
    "print(f\"‚úì Filled {proc_missing} missing procurement methods with 'Unknown'\")\n",
    "\n",
    "# Fix 3: Handle missing dates (REMOVE these rows)\n",
    "date_missing = data['pub_date'].isna().sum()\n",
    "if date_missing > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è  Found {date_missing} rows with missing dates\")\n",
    "    print(\"   Removing these rows (dates are critical for fraud analysis)\")\n",
    "    data = data[data['pub_date'].notna()]  # Keep only rows with valid dates\n",
    "    print(f\"‚úì Removed {date_missing} rows with missing dates\")\n",
    "\n",
    "# Show current missing values\n",
    "print(\"\\nüìä Missing values AFTER handling:\")\n",
    "remaining_missing = data.isnull().sum()\n",
    "print(remaining_missing)\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n‚úÖ Data ready for feature engineering!\")\n",
    "print(f\"   Final record count: {len(data):,}\")\n",
    "print(f\"   Columns with no missing values: {(remaining_missing == 0).sum()}/{len(remaining_missing)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf26d936",
   "metadata": {},
   "source": [
    "DATE FEATURE EXTRACTION (My Design):\n",
    "\n",
    "From publication date, I'm extracting:\n",
    "- year: To see trends over time\n",
    "- month: To detect year-end rush (Dec/March)\n",
    "- day_of_week: To catch weekend awards (suspicious)\n",
    "- quarter: For quarterly analysis\n",
    "\n",
    "Why? Timing is critical in procurement fraud detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95d51cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÖ Extracting date features...\n",
      "‚úì Created date-based features:\n",
      "   - tender_year (range:2022-2022)\n",
      "   - tender_month (1-12)\n",
      "   - day_of_week (0-6)\n",
      "   - quarter (1-4)\n"
     ]
    }
   ],
   "source": [
    "print(\"üìÖ Extracting date features...\")\n",
    "\n",
    "# Extract year\n",
    "data['tender_year'] = data['pub_date'].dt.year\n",
    "\n",
    "# Extract month (1-12)\n",
    "data['tender_month'] = data['pub_date'].dt.month\n",
    "\n",
    "# Extract day of week (0=Monday, 6=Sunday)\n",
    "data['day_of_week'] = data['pub_date'].dt.dayofweek\n",
    "\n",
    "# Calculate quarter (Q1-Q4)\n",
    "data['quarter'] = data['pub_date'].dt.quarter\n",
    "\n",
    "# Create readable month names for later visualization\n",
    "month_names = {1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun',\n",
    "               7: 'Jul', 8: 'Aug', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dec'}\n",
    "data['month_name'] = data['tender_month'].map(month_names)\n",
    "\n",
    "print(\"‚úì Created date-based features:\")\n",
    "print(f\"   - tender_year (range:{data['tender_year'].min()}-{data['tender_year'].max()})\")\n",
    "print(f\"   - tender_month (1-12)\")\n",
    "print(f\"   - day_of_week (0-6)\")\n",
    "print(f\"   - quarter (1-4)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f8c77e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ PREPROCESSING COMPLETE\n",
      "   Original columns: 7\n",
      "   Final columns:12\n",
      "   Records ready for feature engineering:26,205\n",
      "\n",
      "üíæ Saved to: data/processed/preprocessed_data.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 26205 entries, 0 to 26204\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   contract_id      26205 non-null  object        \n",
      " 1   pub_date         26205 non-null  datetime64[ns]\n",
      " 2   contract_amount  26205 non-null  float64       \n",
      " 3   bidder_count     26205 non-null  float64       \n",
      " 4   dept_name        26205 non-null  object        \n",
      " 5   proc_method      26205 non-null  object        \n",
      " 6   data_source      26205 non-null  object        \n",
      " 7   tender_year      26205 non-null  int32         \n",
      " 8   tender_month     26205 non-null  int32         \n",
      " 9   day_of_week      26205 non-null  int32         \n",
      " 10  quarter          26205 non-null  int32         \n",
      " 11  month_name       26205 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(2), int32(4), object(5)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Save preprocessed dataset\n",
    "data.to_csv('data/processed/preprocessed_data.csv', index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ PREPROCESSING COMPLETE\")\n",
    "print(f\"   Original columns: 7\")\n",
    "print(f\"   Final columns:{len(data.columns)}\")\n",
    "print(f\"   Records ready for feature engineering:{len(data):,}\")\n",
    "print(f\"\\nüíæ Saved to: data/processed/preprocessed_data.csv\")\n",
    "\n",
    "# Display summary\n",
    "data.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
